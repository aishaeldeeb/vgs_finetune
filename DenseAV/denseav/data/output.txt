self.train_dataset.__getitem__(1)


 /Users/aishaeldeeb/Desktop/VGS/DenseAV/denseav/data/AVDatasets.py(202)_filter_valid_metadata()
-> if (percent_missing <= self._missing_threshold()):
(Pdb) df[df["is_valid"]]
     caption_id  img_id  ...                                        frame_files is_valid
0          1_01       1  ...  [/Users/aishaeldeeb/Desktop/VGS/vis_text/frame...     True
1          2_01       2  ...  [/Users/aishaeldeeb/Desktop/VGS/vis_text/frame...     True
9969       1_01       1  ...  [/Users/aishaeldeeb/Desktop/VGS/vis_text/frame...     True
9970       2_01       2  ...  [/Users/aishaeldeeb/Desktop/VGS/vis_text/frame...     True

[4 rows x 15 columns]


        loader= DataLoader(self.train_dataset, shuffle=True, **self.loader_args, collate_fn=custom_coallate)

 df[df["is_valid"]]["frame_files"].iloc[0]
(my_env) aishaeldeeb@Aishas-MBP denseav % python train.py 
code_dim: 384
image_model_type: dino8
image_model_token_type: token
image_aligner_type: image_linear
image_pool_width: 2
audio_model_type: hubert
audio_aligner_type: audio_sa_3_3_pool_2
audio_pool_width: 1
learn_audio_cls: true
audio_lora: true
audio_lora_rank: 8
image_lora: true
image_lora_rank: 8
spatial_dropout: 0.0
channel_dropout: 0.0
quad_mixup: 0.1
bg_mixup: 0.0
patch_mixup: 0.0
mixup_weight: 0.1
sim_agg_type: misa
sim_agg_heads: 1
sim_use_cls: false
cal_init: 1.0
cal_balance_weight: 0.1
nonneg_sim: false
nonneg_pressure: 0.01
silence_l1: 0.01
silence_l2: 0.0
tv_weight: 0.01
specialization_weight: 0.05
head_agg: max_elementwise
disentangle_weight: 0.0
norm_vectors: false
neg_audio: true
neg_audio_weight: 0.01
pretrain_steps: 3000
pretrain_lr: 5.0e-05
lr: 5.0e-05
lr_warmup: 1000
lr_schedule: null
lr_cycle_length: 50000
optimizer: adam
gradient_clipping: 10.0
adaptive_clipping: true
gather_tensors: true
loss_type: nce
loss_leak: 0.0
loss_margin: 0.0
mask_silence: true
extra_audio_masking: true
max_steps: 1000001
finetune_image_model: true
finetune_audio_model: true
load_strict: true
starting_weights: null
auto_resume: false
grouping_name: first_grouping
resume_prefix: vis_text
dataset_name: vistext
use_extra_val_sets: false
batch_size: 1
load_size: 224
image_aug: true
audio_aug: false
audio_level: false
memory_buffer_size: 0
val_check_interval: 1
use_cached_embs: false
num_workers: 0
num_gpus: 4
num_sanity_val_steps: 0
seed: 0
output_root: ../
pytorch_data_dir: /Users/aishaeldeeb/Desktop/VGS/
submitting_to_aml: false

Global seed set to 0
Using cache found in /Users/aishaeldeeb/.cache/torch/hub/facebookresearch_dino_main
trainable params: 147,456 || all params: 21,817,728 || trainable%: 0.6758540577644016
trainable params: 1,179,648 || all params: 316,618,368 || trainable%: 0.3725772473187658
Starting pretrain phase
Using 16bit None Automatic Mixed Precision (AMP)
/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/native_amp.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Number of files processed during the train stage 19938
100%|█████████████████████████████████████████████████| 19938/19938 [00:00<00:00, 152719.58it/s]
100%|█████████████████████████████████████████████████| 19938/19938 [00:00<00:00, 174944.00it/s]
MY_DIR  ['/Users/aishaeldeeb/Desktop/VGS/vis_text/frames', '/Users/aishaeldeeb/Desktop/VGS/vis_text/audio', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_train.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_test.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_val.json']
ALL AUDIO  9
ALL FRAMES  9
Number of files processed during the val stage 2404
100%|███████████████████████████████████████████████████| 2404/2404 [00:00<00:00, 163413.56it/s]
100%|███████████████████████████████████████████████████| 2404/2404 [00:00<00:00, 166034.46it/s]
MY_DIR  ['/Users/aishaeldeeb/Desktop/VGS/vis_text/frames', '/Users/aishaeldeeb/Desktop/VGS/vis_text/audio', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_train.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_test.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_val.json']
ALL AUDIO  9
ALL FRAMES  9
Not using val subset
/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory ../checkpoints/first_grouping/vis_text/pretrain exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")

  | Name          | Type                     | Params
-----------------------------------------------------------
0 | image_model   | PeftModel                | 21.8 M
1 | audio_model   | PeftModel                | 316 M 
2 | audio_aligner | Sequential2              | 3.8 M 
3 | image_aligner | LinearAligner            | 296 K 
4 | sim_cal       | SimilarityCalibrator     | 1     
5 | sim_agg       | ImageThenAudioAggregator | 0     
-----------------------------------------------------------
5.4 M     Trainable params
337 M     Non-trainable params
342 M     Total params
685.053   Total estimated model params size (MB)
/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Epoch 0:   0%|                                                            | 0/4 [00:00<?, ?it/s]/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
Epoch 0:  25%|███████▌                      | 1/4 [00:36<01:48, 36.09s/it, loss=0.265, v_num=50]WARNING: No negative samples found in batch
Epoch 1:  25%|███████▊                       | 1/4 [00:01<00:04,  1.49s/it, loss=0.25, v_num=50]WARNING: No negative samples found in batch
Epoch 1:  75%|███████████████████████▎       | 3/4 [00:05<00:01,  1.99s/it, loss=0.23, v_num=50]WARNING: No negative samples found in batch
Epoch 1: 100%|██████████████████████████████| 4/4 [00:08<00:00,  2.06s/it, loss=0.208, v_num=50]`Trainer.fit` stopped: `max_epochs=2` reached.
Epoch 1: 100%|██████████████████████████████| 4/4 [00:08<00:00,  2.06s/it, loss=0.208, v_num=50]
Starting train phase
Using 16bit None Automatic Mixed Precision (AMP)
/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/native_amp.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Number of files processed during the train stage 19938
100%|█████████████████████████████████████████████████| 19938/19938 [00:00<00:00, 192825.78it/s]
100%|█████████████████████████████████████████████████| 19938/19938 [00:00<00:00, 188323.59it/s]
MY_DIR  ['/Users/aishaeldeeb/Desktop/VGS/vis_text/frames', '/Users/aishaeldeeb/Desktop/VGS/vis_text/audio', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_train.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_test.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_val.json']
ALL AUDIO  9
ALL FRAMES  9
Number of files processed during the val stage 2404
100%|███████████████████████████████████████████████████| 2404/2404 [00:00<00:00, 138138.00it/s]
100%|███████████████████████████████████████████████████| 2404/2404 [00:00<00:00, 163114.84it/s]
MY_DIR  ['/Users/aishaeldeeb/Desktop/VGS/vis_text/frames', '/Users/aishaeldeeb/Desktop/VGS/vis_text/audio', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_train.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_test.json', '/Users/aishaeldeeb/Desktop/VGS/vis_text/data_val.json']
ALL AUDIO  9
ALL FRAMES  9
Not using val subset

  | Name          | Type                     | Params
-----------------------------------------------------------
0 | image_model   | PeftModel                | 21.8 M
1 | audio_model   | PeftModel                | 316 M 
2 | audio_aligner | Sequential2              | 3.8 M 
3 | image_aligner | LinearAligner            | 296 K 
4 | sim_cal       | SimilarityCalibrator     | 1     
5 | sim_agg       | ImageThenAudioAggregator | 0     
-----------------------------------------------------------
5.4 M     Trainable params
337 M     Non-trainable params
342 M     Total params
685.053   Total estimated model params size (MB)
/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Epoch 0:   0%|                                                            | 0/4 [00:00<?, ?it/s]/Users/aishaeldeeb/Desktop/VGS/my_env/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
WARNING: No negative samples found in batch
Epoch 0:  25%|███████▊                       | 1/4 [00:25<01:15, 25.19s/it, loss=0.127, v_num=2]

